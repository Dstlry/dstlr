{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%AddDeps com.lucidworks.spark spark-solr 3.6.0 --transitive\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.9.2 --transitive\n",
    "%AddDeps edu.stanford.nlp stanford-corenlp 3.9.2 --classifier models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Documents from Solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.lucidworks.spark.rdd.SelectSolrRDD\n",
    "\n",
    "val SOLR = \"localhost:9990\"\n",
    "\n",
    "val INDEX = \"core17\"\n",
    "val FIELD = \"contents\"\n",
    "val QUERY = \"Obama\"\n",
    "\n",
    "val rdd = new SelectSolrRDD(SOLR, INDEX, sc)\n",
    "    .rows(1000)\n",
    "    .query(FIELD + \":\" + QUERY)\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoreNLP Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collection.JavaConversions._\n",
    "import edu.stanford.nlp.simple._\n",
    "\n",
    "val doc = new Document(\"Barrack Obama was born in Hawaii. He is our president.\")\n",
    "\n",
    "for (sent <- doc.sentences()) {\n",
    "    for (triple <- sent.openieTriples()) {\n",
    "        println(s\"(${triple.subjectLemmaGloss()}, ${triple.relationLemmaGloss()}, ${triple.objectLemmaGloss()})\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solr + Spark + CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collection.mutable.ListBuffer\n",
    "import collection.JavaConversions._\n",
    "\n",
    "import com.lucidworks.spark.rdd.SelectSolrRDD\n",
    "import edu.stanford.nlp.simple.Document\n",
    "\n",
    "val SOLR = \"localhost:9990\"\n",
    "\n",
    "val INDEX = \"core17\"\n",
    "val FIELD = \"contents\"\n",
    "val QUERY = \"Obama\"\n",
    "\n",
    "val rdd = new SelectSolrRDD(SOLR, INDEX, sc)\n",
    "    .rows(1000)\n",
    "    .query(FIELD + \":\" + QUERY)\n",
    "    .map(d => {\n",
    "        \n",
    "        val list = new ListBuffer[Tuple3[String, String, String]]()\n",
    "        val doc = new Document(d.get(\"raw\").asInstanceOf[String])\n",
    "        \n",
    "        for (sent <- doc.sentences()) {\n",
    "            for (triple <- sent.openieTriples()) {\n",
    "                list.append((triple.subjectLemmaGloss(), triple.relationLemmaGloss(), triple.objectLemmaGloss()))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        (d.get(\"id\"), list.toList)\n",
    "        \n",
    "    })\n",
    "\n",
    "val doc = rdd.take(1)\n",
    "\n",
    "println(doc.head._1)\n",
    "doc.head._2.foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
